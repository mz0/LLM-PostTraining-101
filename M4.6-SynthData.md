
0:00
Synthetic data can be a really effective way to scale out your datasets, but on its own,
0:05
it can be kind of noisy. In this video, you'll learn how to make it really high quality
0:09
to generate, filter, score, and transform your data with language models.
0:14
All right, so here's a key question. Why use synthetic data pipelines? Why use LLMs to help
0:19
you? People are amazing at judgment, and if you ask people to rank different answers,
0:23
they'll usually get it right. But the problem is they're slow, we're expensive, you know,
0:27
especially experts. And on the other hand, synthetic signals are probably the opposite,
0:31
right? They're super fast, they're cheaper, they can scale. Maybe they're not crazy cheap if you're
0:35
going for a huge amount. But instead of a handful of human labels in an hour, you can generate
0:40
thousands of synthetic pairs at the same time. But the catch is usually around quality,
0:44
and just, you know, the generated samples might just be kind of generic. And if you just take it
0:49
at face value, that speed just turns into noise, and that noise is not useful for actually improving
0:56
the model. So take a look at how you can actually create synthetic data that will be actually
1:00
useful for your post-training pipelines. So you already saw this a little bit before around
1:05
constitutional AI, but Anthropic that came up with constitutional AI uses synthetic data in
1:10
a really effective way, and uses synthetic pipelines in a very effective way by getting
1:14
the human to mainly focus on writing the constitution itself. But apart from that,
1:18
just using synthetic pipelines to transform that constitution into different ways of both
1:24
critiquing model outputs and also selecting better outputs that follow that constitution.
1:28
So I think this is a really, really great way of scaling things out and using human labor and human
1:35
expertise in areas where we shine, and then scaling it out with language models.
1:40
So there are a few key areas where language models can be really helpful. One is obviously
1:44
generating a ton of data. The other one is, however, filtering that data and filtering it to
1:49
actually high quality data. This is pretty important to have really good filtering,
1:54
because then you can kind of go ham with generating. You can go further with generating.
1:58
Next is transforming that data. I think this is actually underutilized today. There's a lot of
2:03
great data just in the wrong format for fine-tuning, for example, and we can actually transform
2:08
it to be very useful. And then finally, scoring, similar to filtering, but scoring that data can
2:13
be useful for preference learning. So going through each of them, starting with generating
2:17
data. So you can use a lot of prompt templates. For example, here you can solve this coding
2:22
question step by step and then have a variable for the question. You can loop through a bunch
2:26
of questions and generate data that way. That way you kind of loop through data or information you
2:32
already have, and you can get a big diversity of that data. You can vary that diversity also
2:37
via different parameters like temperature, so the model can actually go more creative and further
2:42
in terms of what it's outputting. So you're going to generate a bunch of data. Some of it is going
2:46
to go well. Some of it you're going to pass on. One problem with passing on data is that you might
2:52
find that there are certain types of inputs where your model just doesn't do well at all. That's
2:57
generating a lot of this data. And as a result, you won't get any data coverage for that type
3:02
of input. So how do you mitigate against that? Well, rejection sampling is one of those methods.
3:07
And what rejection sampling essentially is, is generating a bunch of possible outputs like here,
3:11
A, B, and C, and just keeping the best N, in this case, the best one out of three.
3:16
So this would be three to one filtering. But essentially, you could scale that to any number,
3:20
any K. You could run more than three outputs, of course, and you can select more than one,
3:24
of course, as well. But this makes it so that you pick the best option out of many possible options
3:30
so that you're more likely to have this input be represented in your dataset. Rejection sampling,
3:35
you can also filter with an LLM as judge. So the LLM as judge could instead be filtering based on
3:40
a constitution, like you saw with Constitutional AI, and some kind of ranking or scoring or
3:45
agreement across these methods. So the majority vote, for example. Filtering your data with LLMs
3:50
in rejection sampling, basically, this is what you did with Constitutional AI, right? You can
3:54
generate a bunch of candidates. With your constitution, your LLM judge will eliminate
3:59
the bad ones. You can run pairwise preferences on what's remained and based on that, get a ranking.
4:05
And then you can check the agreement with self-consistency or majority vote. And then
4:09
you select the top N as the filtered high signal examples that you can then apply to your dataset.
4:15
So filtering just helps you mainly from training on noise, and you really want to avoid that
4:19
because you can actually get away with, again, that smaller high-quality dataset over a large
4:23
noisy dataset in terms of improving your model. So data generation is only as useful as your
4:29
filtering since, again, if you generate a bunch of noisy data, it's not going to be useful.
4:34
So having good filtering will enable you to go harder on the generation side. For all of AI,
4:40
it's garbage in, garbage out. So make sure that you are putting in high-quality data. Filtering
4:46
can be using language models and, of course, using different types of verification that's
4:50
more programmatic as well. Cool. So some ways to filter, you can use a template like the one you
4:55
see here around solve this coding question using a different method. So verifying the previous
5:01
method and using a heavier chain of thought to do a double check, essentially, of your model's
5:06
previous output. Something else to look for is collapse detection. So you don't want a lot of
5:11
redundant input-output pairs, for example. You want to remove redundancy if it's not actually
5:17
giving you additional information. So filtering can also be very useful here, essentially a dedupe
5:21
or a soft dedupe. Finally, using majority voting can help you hone in on which possible answer
5:28
is actually most likely to be correct. Moving on to transforming data. Again, I think this is
5:33
super underutilized, so please focus here a little bit. But one way to transform data is, let's say,
5:39
the model produces something really, really verbose. Here, you can transform it to be
5:44
significantly more succinct. As an example, other ways is to standardize the tone or style of your
5:49
dataset or augment your dataset in different ways, expand it with step-by-step versions.
5:54
We have previously seen that it's helpful for these models to see data of the right difficulty
6:00
to train on it, right? So bucketing things into easy versus harder tasks or moderately difficult
6:06
tasks can be very helpful in this stage as well. Finally, let's get to scoring. So scoring data
6:11
with LLMs is possible just by asking the LLM for a score. Sometimes it's more effective to also ask
6:18
for a score across different axes that you care about, maybe present in your constitution. That
6:24
helps you get a more reliable score across dimensions that you actually care about.
6:29
So in your code, what this could look like is you could actually extract step indicators. So like
6:35
from the model's output, you could see the model thinking step-by-step, like first do this, second
6:39
do this, third do this, and then calculate this or multiply this. This is for math in particular.
6:45
And you could actually count how many steps it's taking, what kind of steps it's taking,
6:50
and give it partial credit based on this as well. So this is a type of scoring. You can also
6:54
extract explanation phrases like because, since, this means, and give it partial credit there as
7:01
well. So there are a lot of different ways to score your model, and this is just a few different
7:05
ways to actually give it a better sense of how it's doing. Now that you're comfortable using LLMs
7:11
to generate synthetic data for you, take a look at how to take it to the next level with templates.
