## GPT-2 (2018 – 2019)
* Data: WebText (~40 GB, curated Reddit outbound links).
* Pretraining: 1.5 B-param decoder-only Transformer, next-token objective.
* Evaluation: Zero-shot text generation, summarization, translation, QA.
* Result: Showed unsupervised multitask ability; partial → full release.

## GPT-3 (2019 – 2020)
* Data: ~570 GB (Common Crawl + WebText2 + Books + Wiki).
* Pretraining: 175 B params, 96 layers; trained for months on V100 GPUs.
* Evaluation: 40 + tasks in zero/one/few-shot; strong few-shot reasoning.
* Result: Established scaling laws; commercialized via OpenAI API.

## GPT-3.5 (2021 – 2022)
* Data: Expanded + code/data mixture (e.g. GitHub, forums).
* Pretraining: 175 B model retrained with refined data filters & RLHF.
* Evaluation: Conversational, reasoning, and code generation tests.
* Result: Served as base for ChatGPT (Dec 2022); stable dialogue tuning.

## GPT-4 (2022 – 2023)
* Data: Broader multilingual + multimodal corpus (text + image alt-text).
* Pretraining: Estimated ~1 T params (Mixture-of-Experts, sparse activation).
* Post-training: RLHF v2 + constitutional feedback for safety & accuracy.
* Evaluation: Standard NLP benchmarks + professional exams + image input.
* Result: Stronger reasoning, factuality, and cross-modal capability.

## GPT-4 Turbo / GPT-4o (2023 – 2024)
* Data: Optimized and continuously updated corpus.
* Training: Unified omnimodal (text, image, audio) pretraining.
* Evaluation: Real-time reasoning, latency + cost + accuracy trade-offs.
* Result: Integrated multimodality and faster inference for ChatGPT Plus.

## GPT-5 (2024 – 2025)
* Data: Larger, higher-quality multi-domain & temporal corpus (web + structured + interactive).
* Training: Unified multi-modal, multi-turn context window (100 k + tokens).
* Post-training: Advanced RLHF + RLAIF (reinforcement from AI feedback).
* Evaluation: Long-horizon reasoning, planning, multi-agent coordination, tool use.
* Result: Transition from pure language modeling → general reasoning agent.

## Overall Evolution (in one line)
* GPT-2: Scale up text modeling
* GPT-3: Few-shot generalization
* GPT-3.5: Dialogue & RLHF
* GPT-4: Multimodal & reasoning
* GPT-5: Long-context, unified multimodal intelligence.
